{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6894174422612892,
  "eval_steps": 500,
  "global_step": 20000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003447087211306446,
      "grad_norm": 4.303680419921875,
      "learning_rate": 4.991468459152017e-05,
      "loss": 1.223,
      "step": 100
    },
    {
      "epoch": 0.006894174422612892,
      "grad_norm": 6.470364570617676,
      "learning_rate": 4.982850741123751e-05,
      "loss": 0.5344,
      "step": 200
    },
    {
      "epoch": 0.010341261633919338,
      "grad_norm": 4.853041648864746,
      "learning_rate": 4.9742330230954845e-05,
      "loss": 0.4274,
      "step": 300
    },
    {
      "epoch": 0.013788348845225784,
      "grad_norm": 6.502013683319092,
      "learning_rate": 4.965615305067218e-05,
      "loss": 0.3648,
      "step": 400
    },
    {
      "epoch": 0.01723543605653223,
      "grad_norm": 5.3957133293151855,
      "learning_rate": 4.956997587038952e-05,
      "loss": 0.3569,
      "step": 500
    },
    {
      "epoch": 0.020682523267838676,
      "grad_norm": 4.524236679077148,
      "learning_rate": 4.948379869010686e-05,
      "loss": 0.3007,
      "step": 600
    },
    {
      "epoch": 0.024129610479145122,
      "grad_norm": 4.2124810218811035,
      "learning_rate": 4.93976215098242e-05,
      "loss": 0.2851,
      "step": 700
    },
    {
      "epoch": 0.027576697690451568,
      "grad_norm": 6.982564926147461,
      "learning_rate": 4.931144432954154e-05,
      "loss": 0.2834,
      "step": 800
    },
    {
      "epoch": 0.031023784901758014,
      "grad_norm": 4.659258842468262,
      "learning_rate": 4.922526714925888e-05,
      "loss": 0.2838,
      "step": 900
    },
    {
      "epoch": 0.03447087211306446,
      "grad_norm": 3.9055016040802,
      "learning_rate": 4.913908996897622e-05,
      "loss": 0.2489,
      "step": 1000
    },
    {
      "epoch": 0.037917959324370906,
      "grad_norm": 2.5169425010681152,
      "learning_rate": 4.905291278869356e-05,
      "loss": 0.2396,
      "step": 1100
    },
    {
      "epoch": 0.04136504653567735,
      "grad_norm": 3.283289670944214,
      "learning_rate": 4.8966735608410893e-05,
      "loss": 0.2269,
      "step": 1200
    },
    {
      "epoch": 0.0448121337469838,
      "grad_norm": 3.807817220687866,
      "learning_rate": 4.888055842812823e-05,
      "loss": 0.2295,
      "step": 1300
    },
    {
      "epoch": 0.048259220958290244,
      "grad_norm": 2.6571078300476074,
      "learning_rate": 4.879438124784557e-05,
      "loss": 0.2062,
      "step": 1400
    },
    {
      "epoch": 0.05170630816959669,
      "grad_norm": 3.571770429611206,
      "learning_rate": 4.870820406756291e-05,
      "loss": 0.2151,
      "step": 1500
    },
    {
      "epoch": 0.055153395380903136,
      "grad_norm": 2.098726987838745,
      "learning_rate": 4.8622026887280254e-05,
      "loss": 0.2091,
      "step": 1600
    },
    {
      "epoch": 0.05860048259220958,
      "grad_norm": 2.646780014038086,
      "learning_rate": 4.853584970699759e-05,
      "loss": 0.2085,
      "step": 1700
    },
    {
      "epoch": 0.06204756980351603,
      "grad_norm": 3.6178131103515625,
      "learning_rate": 4.844967252671493e-05,
      "loss": 0.2135,
      "step": 1800
    },
    {
      "epoch": 0.06549465701482247,
      "grad_norm": 3.263490676879883,
      "learning_rate": 4.836349534643227e-05,
      "loss": 0.1923,
      "step": 1900
    },
    {
      "epoch": 0.06894174422612892,
      "grad_norm": 3.211461305618286,
      "learning_rate": 4.827731816614961e-05,
      "loss": 0.1832,
      "step": 2000
    },
    {
      "epoch": 0.07238883143743537,
      "grad_norm": 2.8188517093658447,
      "learning_rate": 4.819114098586694e-05,
      "loss": 0.1924,
      "step": 2100
    },
    {
      "epoch": 0.07583591864874181,
      "grad_norm": 2.6957290172576904,
      "learning_rate": 4.8104963805584284e-05,
      "loss": 0.1903,
      "step": 2200
    },
    {
      "epoch": 0.07928300586004826,
      "grad_norm": 4.769791603088379,
      "learning_rate": 4.801878662530162e-05,
      "loss": 0.2005,
      "step": 2300
    },
    {
      "epoch": 0.0827300930713547,
      "grad_norm": 1.9941500425338745,
      "learning_rate": 4.793260944501896e-05,
      "loss": 0.18,
      "step": 2400
    },
    {
      "epoch": 0.08617718028266115,
      "grad_norm": 2.944767713546753,
      "learning_rate": 4.78464322647363e-05,
      "loss": 0.1637,
      "step": 2500
    },
    {
      "epoch": 0.0896242674939676,
      "grad_norm": 2.3305060863494873,
      "learning_rate": 4.776025508445364e-05,
      "loss": 0.1641,
      "step": 2600
    },
    {
      "epoch": 0.09307135470527404,
      "grad_norm": 2.8339264392852783,
      "learning_rate": 4.767407790417098e-05,
      "loss": 0.1679,
      "step": 2700
    },
    {
      "epoch": 0.09651844191658049,
      "grad_norm": 3.2620275020599365,
      "learning_rate": 4.7587900723888315e-05,
      "loss": 0.1699,
      "step": 2800
    },
    {
      "epoch": 0.09996552912788693,
      "grad_norm": 2.910306930541992,
      "learning_rate": 4.750172354360565e-05,
      "loss": 0.1595,
      "step": 2900
    },
    {
      "epoch": 0.10341261633919338,
      "grad_norm": 4.5352582931518555,
      "learning_rate": 4.741554636332299e-05,
      "loss": 0.4303,
      "step": 3000
    },
    {
      "epoch": 0.10685970355049983,
      "grad_norm": 3.213740825653076,
      "learning_rate": 4.732936918304033e-05,
      "loss": 0.1484,
      "step": 3100
    },
    {
      "epoch": 0.11030679076180627,
      "grad_norm": 2.0462887287139893,
      "learning_rate": 4.7243192002757675e-05,
      "loss": 0.1598,
      "step": 3200
    },
    {
      "epoch": 0.11375387797311272,
      "grad_norm": 1.7438653707504272,
      "learning_rate": 4.715701482247501e-05,
      "loss": 0.1605,
      "step": 3300
    },
    {
      "epoch": 0.11720096518441916,
      "grad_norm": 3.414728879928589,
      "learning_rate": 4.707083764219235e-05,
      "loss": 0.1572,
      "step": 3400
    },
    {
      "epoch": 0.12064805239572561,
      "grad_norm": 1.9016185998916626,
      "learning_rate": 4.6984660461909694e-05,
      "loss": 0.1639,
      "step": 3500
    },
    {
      "epoch": 0.12409513960703206,
      "grad_norm": 2.628908395767212,
      "learning_rate": 4.689848328162703e-05,
      "loss": 0.1457,
      "step": 3600
    },
    {
      "epoch": 0.12754222681833852,
      "grad_norm": 2.9661076068878174,
      "learning_rate": 4.6812306101344364e-05,
      "loss": 0.1524,
      "step": 3700
    },
    {
      "epoch": 0.13098931402964495,
      "grad_norm": 4.158839225769043,
      "learning_rate": 4.6726128921061705e-05,
      "loss": 0.145,
      "step": 3800
    },
    {
      "epoch": 0.1344364012409514,
      "grad_norm": 3.2656660079956055,
      "learning_rate": 4.663995174077904e-05,
      "loss": 0.1428,
      "step": 3900
    },
    {
      "epoch": 0.13788348845225784,
      "grad_norm": 3.5795106887817383,
      "learning_rate": 4.655377456049638e-05,
      "loss": 0.148,
      "step": 4000
    },
    {
      "epoch": 0.1413305756635643,
      "grad_norm": 1.6617783308029175,
      "learning_rate": 4.6467597380213724e-05,
      "loss": 0.1336,
      "step": 4100
    },
    {
      "epoch": 0.14477766287487073,
      "grad_norm": 1.2152483463287354,
      "learning_rate": 4.638142019993106e-05,
      "loss": 0.1468,
      "step": 4200
    },
    {
      "epoch": 0.1482247500861772,
      "grad_norm": 3.912557363510132,
      "learning_rate": 4.62952430196484e-05,
      "loss": 0.1518,
      "step": 4300
    },
    {
      "epoch": 0.15167183729748362,
      "grad_norm": 2.529700517654419,
      "learning_rate": 4.620906583936574e-05,
      "loss": 0.1428,
      "step": 4400
    },
    {
      "epoch": 0.15511892450879008,
      "grad_norm": 2.831672191619873,
      "learning_rate": 4.612288865908308e-05,
      "loss": 0.1314,
      "step": 4500
    },
    {
      "epoch": 0.15856601172009652,
      "grad_norm": 1.0336251258850098,
      "learning_rate": 4.603671147880041e-05,
      "loss": 0.1311,
      "step": 4600
    },
    {
      "epoch": 0.16201309893140298,
      "grad_norm": 4.659207820892334,
      "learning_rate": 4.5950534298517754e-05,
      "loss": 0.1365,
      "step": 4700
    },
    {
      "epoch": 0.1654601861427094,
      "grad_norm": 3.007638454437256,
      "learning_rate": 4.5864357118235096e-05,
      "loss": 0.1387,
      "step": 4800
    },
    {
      "epoch": 0.16890727335401587,
      "grad_norm": 2.562551498413086,
      "learning_rate": 4.577817993795243e-05,
      "loss": 0.1363,
      "step": 4900
    },
    {
      "epoch": 0.1723543605653223,
      "grad_norm": 2.8717164993286133,
      "learning_rate": 4.569200275766977e-05,
      "loss": 0.1316,
      "step": 5000
    },
    {
      "epoch": 0.17580144777662876,
      "grad_norm": 2.566441297531128,
      "learning_rate": 4.5605825577387115e-05,
      "loss": 0.1449,
      "step": 5100
    },
    {
      "epoch": 0.1792485349879352,
      "grad_norm": 1.6927716732025146,
      "learning_rate": 4.551964839710445e-05,
      "loss": 0.1358,
      "step": 5200
    },
    {
      "epoch": 0.18269562219924165,
      "grad_norm": 2.3892478942871094,
      "learning_rate": 4.5433471216821785e-05,
      "loss": 0.1417,
      "step": 5300
    },
    {
      "epoch": 0.18614270941054809,
      "grad_norm": 1.2469395399093628,
      "learning_rate": 4.5347294036539127e-05,
      "loss": 0.1357,
      "step": 5400
    },
    {
      "epoch": 0.18958979662185454,
      "grad_norm": 1.928580641746521,
      "learning_rate": 4.526111685625646e-05,
      "loss": 0.124,
      "step": 5500
    },
    {
      "epoch": 0.19303688383316098,
      "grad_norm": 2.4810993671417236,
      "learning_rate": 4.5174939675973803e-05,
      "loss": 0.1279,
      "step": 5600
    },
    {
      "epoch": 0.19648397104446744,
      "grad_norm": 2.812318801879883,
      "learning_rate": 4.5088762495691145e-05,
      "loss": 0.1319,
      "step": 5700
    },
    {
      "epoch": 0.19993105825577387,
      "grad_norm": 2.90177321434021,
      "learning_rate": 4.500258531540848e-05,
      "loss": 0.1229,
      "step": 5800
    },
    {
      "epoch": 0.20337814546708033,
      "grad_norm": 0.8568460941314697,
      "learning_rate": 4.491640813512582e-05,
      "loss": 0.1226,
      "step": 5900
    },
    {
      "epoch": 0.20682523267838676,
      "grad_norm": 1.6732901334762573,
      "learning_rate": 4.4830230954843164e-05,
      "loss": 0.1264,
      "step": 6000
    },
    {
      "epoch": 0.21027231988969322,
      "grad_norm": 2.0360305309295654,
      "learning_rate": 4.47440537745605e-05,
      "loss": 0.1248,
      "step": 6100
    },
    {
      "epoch": 0.21371940710099965,
      "grad_norm": 1.9102096557617188,
      "learning_rate": 4.4657876594277834e-05,
      "loss": 0.1138,
      "step": 6200
    },
    {
      "epoch": 0.2171664943123061,
      "grad_norm": 2.1217901706695557,
      "learning_rate": 4.4571699413995176e-05,
      "loss": 0.113,
      "step": 6300
    },
    {
      "epoch": 0.22061358152361255,
      "grad_norm": 2.3894965648651123,
      "learning_rate": 4.448552223371252e-05,
      "loss": 0.1192,
      "step": 6400
    },
    {
      "epoch": 0.224060668734919,
      "grad_norm": 1.4748977422714233,
      "learning_rate": 4.439934505342985e-05,
      "loss": 0.1248,
      "step": 6500
    },
    {
      "epoch": 0.22750775594622544,
      "grad_norm": 2.8336715698242188,
      "learning_rate": 4.4313167873147194e-05,
      "loss": 0.1231,
      "step": 6600
    },
    {
      "epoch": 0.2309548431575319,
      "grad_norm": 1.7071102857589722,
      "learning_rate": 4.4226990692864536e-05,
      "loss": 0.123,
      "step": 6700
    },
    {
      "epoch": 0.23440193036883833,
      "grad_norm": 6.043149948120117,
      "learning_rate": 4.414081351258187e-05,
      "loss": 0.1184,
      "step": 6800
    },
    {
      "epoch": 0.2378490175801448,
      "grad_norm": 2.4182162284851074,
      "learning_rate": 4.405463633229921e-05,
      "loss": 0.1152,
      "step": 6900
    },
    {
      "epoch": 0.24129610479145122,
      "grad_norm": 1.7427115440368652,
      "learning_rate": 4.396845915201655e-05,
      "loss": 0.1221,
      "step": 7000
    },
    {
      "epoch": 0.24474319200275768,
      "grad_norm": 1.5583312511444092,
      "learning_rate": 4.388228197173388e-05,
      "loss": 0.116,
      "step": 7100
    },
    {
      "epoch": 0.2481902792140641,
      "grad_norm": 1.299799919128418,
      "learning_rate": 4.3796104791451225e-05,
      "loss": 0.1117,
      "step": 7200
    },
    {
      "epoch": 0.25163736642537055,
      "grad_norm": 1.1918904781341553,
      "learning_rate": 4.3709927611168566e-05,
      "loss": 0.106,
      "step": 7300
    },
    {
      "epoch": 0.25508445363667703,
      "grad_norm": 0.7167479991912842,
      "learning_rate": 4.36237504308859e-05,
      "loss": 0.1161,
      "step": 7400
    },
    {
      "epoch": 0.25853154084798347,
      "grad_norm": 1.7980955839157104,
      "learning_rate": 4.353757325060324e-05,
      "loss": 0.1086,
      "step": 7500
    },
    {
      "epoch": 0.2619786280592899,
      "grad_norm": 2.1424477100372314,
      "learning_rate": 4.3451396070320585e-05,
      "loss": 0.1123,
      "step": 7600
    },
    {
      "epoch": 0.26542571527059633,
      "grad_norm": 1.7051892280578613,
      "learning_rate": 4.336521889003792e-05,
      "loss": 0.1138,
      "step": 7700
    },
    {
      "epoch": 0.2688728024819028,
      "grad_norm": 1.5335168838500977,
      "learning_rate": 4.3279041709755255e-05,
      "loss": 0.1151,
      "step": 7800
    },
    {
      "epoch": 0.27231988969320925,
      "grad_norm": 1.5876749753952026,
      "learning_rate": 4.31928645294726e-05,
      "loss": 0.1188,
      "step": 7900
    },
    {
      "epoch": 0.2757669769045157,
      "grad_norm": 2.0134599208831787,
      "learning_rate": 4.310668734918994e-05,
      "loss": 0.1165,
      "step": 8000
    },
    {
      "epoch": 0.2792140641158221,
      "grad_norm": 2.577963352203369,
      "learning_rate": 4.3020510168907274e-05,
      "loss": 0.1121,
      "step": 8100
    },
    {
      "epoch": 0.2826611513271286,
      "grad_norm": 3.4172592163085938,
      "learning_rate": 4.2934332988624615e-05,
      "loss": 0.1043,
      "step": 8200
    },
    {
      "epoch": 0.28610823853843503,
      "grad_norm": 0.7499385476112366,
      "learning_rate": 4.284815580834196e-05,
      "loss": 0.1066,
      "step": 8300
    },
    {
      "epoch": 0.28955532574974147,
      "grad_norm": 1.6316626071929932,
      "learning_rate": 4.276197862805929e-05,
      "loss": 0.1128,
      "step": 8400
    },
    {
      "epoch": 0.2930024129610479,
      "grad_norm": 1.3686579465866089,
      "learning_rate": 4.2675801447776634e-05,
      "loss": 0.1118,
      "step": 8500
    },
    {
      "epoch": 0.2964495001723544,
      "grad_norm": 2.6649558544158936,
      "learning_rate": 4.258962426749397e-05,
      "loss": 0.1162,
      "step": 8600
    },
    {
      "epoch": 0.2998965873836608,
      "grad_norm": 1.6945075988769531,
      "learning_rate": 4.2503447087211304e-05,
      "loss": 0.1253,
      "step": 8700
    },
    {
      "epoch": 0.30334367459496725,
      "grad_norm": 1.6778855323791504,
      "learning_rate": 4.2417269906928646e-05,
      "loss": 0.1091,
      "step": 8800
    },
    {
      "epoch": 0.3067907618062737,
      "grad_norm": 3.7360527515411377,
      "learning_rate": 4.233109272664599e-05,
      "loss": 0.0995,
      "step": 8900
    },
    {
      "epoch": 0.31023784901758017,
      "grad_norm": 2.8926303386688232,
      "learning_rate": 4.224491554636332e-05,
      "loss": 0.105,
      "step": 9000
    },
    {
      "epoch": 0.3136849362288866,
      "grad_norm": 1.2131428718566895,
      "learning_rate": 4.2158738366080664e-05,
      "loss": 0.1068,
      "step": 9100
    },
    {
      "epoch": 0.31713202344019303,
      "grad_norm": 1.9421665668487549,
      "learning_rate": 4.2072561185798006e-05,
      "loss": 0.1026,
      "step": 9200
    },
    {
      "epoch": 0.32057911065149947,
      "grad_norm": 0.8132182955741882,
      "learning_rate": 4.198638400551534e-05,
      "loss": 0.1075,
      "step": 9300
    },
    {
      "epoch": 0.32402619786280595,
      "grad_norm": 1.193691611289978,
      "learning_rate": 4.190020682523268e-05,
      "loss": 0.1089,
      "step": 9400
    },
    {
      "epoch": 0.3274732850741124,
      "grad_norm": 2.4003851413726807,
      "learning_rate": 4.181402964495002e-05,
      "loss": 0.1036,
      "step": 9500
    },
    {
      "epoch": 0.3309203722854188,
      "grad_norm": 1.0666168928146362,
      "learning_rate": 4.172785246466736e-05,
      "loss": 0.1088,
      "step": 9600
    },
    {
      "epoch": 0.33436745949672525,
      "grad_norm": 2.018311023712158,
      "learning_rate": 4.1641675284384695e-05,
      "loss": 0.1107,
      "step": 9700
    },
    {
      "epoch": 0.33781454670803174,
      "grad_norm": 1.8548911809921265,
      "learning_rate": 4.1555498104102037e-05,
      "loss": 0.0988,
      "step": 9800
    },
    {
      "epoch": 0.34126163391933817,
      "grad_norm": 2.5559957027435303,
      "learning_rate": 4.146932092381938e-05,
      "loss": 0.1078,
      "step": 9900
    },
    {
      "epoch": 0.3447087211306446,
      "grad_norm": 1.916216492652893,
      "learning_rate": 4.138314374353671e-05,
      "loss": 0.1024,
      "step": 10000
    },
    {
      "epoch": 0.34815580834195103,
      "grad_norm": 2.1601333618164062,
      "learning_rate": 4.1296966563254055e-05,
      "loss": 0.0958,
      "step": 10100
    },
    {
      "epoch": 0.3516028955532575,
      "grad_norm": 2.2359089851379395,
      "learning_rate": 4.121078938297139e-05,
      "loss": 0.103,
      "step": 10200
    },
    {
      "epoch": 0.35504998276456395,
      "grad_norm": 1.8845174312591553,
      "learning_rate": 4.1124612202688725e-05,
      "loss": 0.1139,
      "step": 10300
    },
    {
      "epoch": 0.3584970699758704,
      "grad_norm": 2.9713528156280518,
      "learning_rate": 4.103843502240607e-05,
      "loss": 0.103,
      "step": 10400
    },
    {
      "epoch": 0.3619441571871768,
      "grad_norm": 1.8375957012176514,
      "learning_rate": 4.095225784212341e-05,
      "loss": 0.1041,
      "step": 10500
    },
    {
      "epoch": 0.3653912443984833,
      "grad_norm": 1.7277710437774658,
      "learning_rate": 4.0866080661840744e-05,
      "loss": 0.0933,
      "step": 10600
    },
    {
      "epoch": 0.36883833160978974,
      "grad_norm": 6.493195056915283,
      "learning_rate": 4.0779903481558086e-05,
      "loss": 0.0975,
      "step": 10700
    },
    {
      "epoch": 0.37228541882109617,
      "grad_norm": 2.000119686126709,
      "learning_rate": 4.069372630127543e-05,
      "loss": 0.101,
      "step": 10800
    },
    {
      "epoch": 0.3757325060324026,
      "grad_norm": 2.278231143951416,
      "learning_rate": 4.060754912099276e-05,
      "loss": 0.0994,
      "step": 10900
    },
    {
      "epoch": 0.3791795932437091,
      "grad_norm": 1.2348655462265015,
      "learning_rate": 4.0521371940710104e-05,
      "loss": 0.0987,
      "step": 11000
    },
    {
      "epoch": 0.3826266804550155,
      "grad_norm": 2.6489057540893555,
      "learning_rate": 4.043519476042744e-05,
      "loss": 0.0964,
      "step": 11100
    },
    {
      "epoch": 0.38607376766632195,
      "grad_norm": 2.4187066555023193,
      "learning_rate": 4.034901758014478e-05,
      "loss": 0.1073,
      "step": 11200
    },
    {
      "epoch": 0.3895208548776284,
      "grad_norm": 1.716210961341858,
      "learning_rate": 4.0262840399862116e-05,
      "loss": 0.097,
      "step": 11300
    },
    {
      "epoch": 0.3929679420889349,
      "grad_norm": 2.162259578704834,
      "learning_rate": 4.017666321957946e-05,
      "loss": 0.0947,
      "step": 11400
    },
    {
      "epoch": 0.3964150293002413,
      "grad_norm": 1.108154535293579,
      "learning_rate": 4.00904860392968e-05,
      "loss": 0.0998,
      "step": 11500
    },
    {
      "epoch": 0.39986211651154774,
      "grad_norm": 2.055893659591675,
      "learning_rate": 4.0004308859014134e-05,
      "loss": 0.0963,
      "step": 11600
    },
    {
      "epoch": 0.40330920372285417,
      "grad_norm": 3.6766319274902344,
      "learning_rate": 3.9918131678731476e-05,
      "loss": 0.1009,
      "step": 11700
    },
    {
      "epoch": 0.40675629093416066,
      "grad_norm": 3.486924171447754,
      "learning_rate": 3.983195449844881e-05,
      "loss": 0.0993,
      "step": 11800
    },
    {
      "epoch": 0.4102033781454671,
      "grad_norm": 1.5805851221084595,
      "learning_rate": 3.974577731816615e-05,
      "loss": 0.1,
      "step": 11900
    },
    {
      "epoch": 0.4136504653567735,
      "grad_norm": 1.3486826419830322,
      "learning_rate": 3.965960013788349e-05,
      "loss": 0.0935,
      "step": 12000
    },
    {
      "epoch": 0.41709755256807995,
      "grad_norm": 1.341402530670166,
      "learning_rate": 3.957342295760083e-05,
      "loss": 0.1012,
      "step": 12100
    },
    {
      "epoch": 0.42054463977938644,
      "grad_norm": 1.126408338546753,
      "learning_rate": 3.9487245777318165e-05,
      "loss": 0.0937,
      "step": 12200
    },
    {
      "epoch": 0.4239917269906929,
      "grad_norm": 1.2470066547393799,
      "learning_rate": 3.940106859703551e-05,
      "loss": 0.0998,
      "step": 12300
    },
    {
      "epoch": 0.4274388142019993,
      "grad_norm": 2.3109686374664307,
      "learning_rate": 3.931489141675285e-05,
      "loss": 0.0967,
      "step": 12400
    },
    {
      "epoch": 0.43088590141330574,
      "grad_norm": 1.8567644357681274,
      "learning_rate": 3.9228714236470183e-05,
      "loss": 0.1012,
      "step": 12500
    },
    {
      "epoch": 0.4343329886246122,
      "grad_norm": 1.1278462409973145,
      "learning_rate": 3.9142537056187525e-05,
      "loss": 0.0957,
      "step": 12600
    },
    {
      "epoch": 0.43778007583591866,
      "grad_norm": 3.039578676223755,
      "learning_rate": 3.905635987590486e-05,
      "loss": 0.1004,
      "step": 12700
    },
    {
      "epoch": 0.4412271630472251,
      "grad_norm": 2.873433828353882,
      "learning_rate": 3.89701826956222e-05,
      "loss": 0.0844,
      "step": 12800
    },
    {
      "epoch": 0.4446742502585315,
      "grad_norm": 0.6576457619667053,
      "learning_rate": 3.888400551533954e-05,
      "loss": 0.0999,
      "step": 12900
    },
    {
      "epoch": 0.448121337469838,
      "grad_norm": 1.427497148513794,
      "learning_rate": 3.879782833505688e-05,
      "loss": 0.0942,
      "step": 13000
    },
    {
      "epoch": 0.45156842468114444,
      "grad_norm": 1.5093605518341064,
      "learning_rate": 3.871165115477422e-05,
      "loss": 0.0877,
      "step": 13100
    },
    {
      "epoch": 0.4550155118924509,
      "grad_norm": 1.3970946073532104,
      "learning_rate": 3.8625473974491556e-05,
      "loss": 0.0912,
      "step": 13200
    },
    {
      "epoch": 0.4584625991037573,
      "grad_norm": 1.160300850868225,
      "learning_rate": 3.85392967942089e-05,
      "loss": 0.087,
      "step": 13300
    },
    {
      "epoch": 0.4619096863150638,
      "grad_norm": 1.6813260316848755,
      "learning_rate": 3.845311961392624e-05,
      "loss": 0.0955,
      "step": 13400
    },
    {
      "epoch": 0.4653567735263702,
      "grad_norm": 1.4102226495742798,
      "learning_rate": 3.8366942433643574e-05,
      "loss": 0.095,
      "step": 13500
    },
    {
      "epoch": 0.46880386073767666,
      "grad_norm": 1.9103056192398071,
      "learning_rate": 3.828076525336091e-05,
      "loss": 0.098,
      "step": 13600
    },
    {
      "epoch": 0.4722509479489831,
      "grad_norm": 1.2846068143844604,
      "learning_rate": 3.819458807307825e-05,
      "loss": 0.0876,
      "step": 13700
    },
    {
      "epoch": 0.4756980351602896,
      "grad_norm": 2.3340556621551514,
      "learning_rate": 3.8108410892795586e-05,
      "loss": 0.1006,
      "step": 13800
    },
    {
      "epoch": 0.479145122371596,
      "grad_norm": 2.207807779312134,
      "learning_rate": 3.802223371251293e-05,
      "loss": 0.0889,
      "step": 13900
    },
    {
      "epoch": 0.48259220958290244,
      "grad_norm": 2.336423873901367,
      "learning_rate": 3.793605653223027e-05,
      "loss": 0.0958,
      "step": 14000
    },
    {
      "epoch": 0.4860392967942089,
      "grad_norm": 0.666114866733551,
      "learning_rate": 3.7849879351947605e-05,
      "loss": 0.0909,
      "step": 14100
    },
    {
      "epoch": 0.48948638400551536,
      "grad_norm": 3.854518175125122,
      "learning_rate": 3.7763702171664946e-05,
      "loss": 0.0928,
      "step": 14200
    },
    {
      "epoch": 0.4929334712168218,
      "grad_norm": 0.5314897298812866,
      "learning_rate": 3.767752499138228e-05,
      "loss": 0.0992,
      "step": 14300
    },
    {
      "epoch": 0.4963805584281282,
      "grad_norm": 2.2364392280578613,
      "learning_rate": 3.759134781109962e-05,
      "loss": 0.0947,
      "step": 14400
    },
    {
      "epoch": 0.49982764563943466,
      "grad_norm": 2.838644027709961,
      "learning_rate": 3.750517063081696e-05,
      "loss": 0.0942,
      "step": 14500
    },
    {
      "epoch": 0.5032747328507411,
      "grad_norm": 6.866163730621338,
      "learning_rate": 3.74189934505343e-05,
      "loss": 0.0941,
      "step": 14600
    },
    {
      "epoch": 0.5067218200620476,
      "grad_norm": 1.662063717842102,
      "learning_rate": 3.733281627025164e-05,
      "loss": 0.091,
      "step": 14700
    },
    {
      "epoch": 0.5101689072733541,
      "grad_norm": 2.812587022781372,
      "learning_rate": 3.724663908996898e-05,
      "loss": 0.1091,
      "step": 14800
    },
    {
      "epoch": 0.5136159944846604,
      "grad_norm": 5.902318954467773,
      "learning_rate": 3.716046190968632e-05,
      "loss": 0.086,
      "step": 14900
    },
    {
      "epoch": 0.5170630816959669,
      "grad_norm": 1.4426779747009277,
      "learning_rate": 3.707428472940366e-05,
      "loss": 0.0897,
      "step": 15000
    },
    {
      "epoch": 0.5205101689072733,
      "grad_norm": 1.8033385276794434,
      "learning_rate": 3.6988107549120995e-05,
      "loss": 0.0858,
      "step": 15100
    },
    {
      "epoch": 0.5239572561185798,
      "grad_norm": 4.197343349456787,
      "learning_rate": 3.690193036883833e-05,
      "loss": 0.0889,
      "step": 15200
    },
    {
      "epoch": 0.5274043433298863,
      "grad_norm": 0.7135761380195618,
      "learning_rate": 3.681575318855567e-05,
      "loss": 0.0996,
      "step": 15300
    },
    {
      "epoch": 0.5308514305411927,
      "grad_norm": 1.3343958854675293,
      "learning_rate": 3.672957600827301e-05,
      "loss": 0.0831,
      "step": 15400
    },
    {
      "epoch": 0.5342985177524991,
      "grad_norm": 3.9947621822357178,
      "learning_rate": 3.664339882799035e-05,
      "loss": 0.0877,
      "step": 15500
    },
    {
      "epoch": 0.5377456049638056,
      "grad_norm": 2.2701070308685303,
      "learning_rate": 3.655722164770769e-05,
      "loss": 0.0982,
      "step": 15600
    },
    {
      "epoch": 0.541192692175112,
      "grad_norm": 1.557679533958435,
      "learning_rate": 3.6471044467425026e-05,
      "loss": 0.0899,
      "step": 15700
    },
    {
      "epoch": 0.5446397793864185,
      "grad_norm": 1.1015371084213257,
      "learning_rate": 3.638486728714237e-05,
      "loss": 0.0921,
      "step": 15800
    },
    {
      "epoch": 0.5480868665977249,
      "grad_norm": 1.7058418989181519,
      "learning_rate": 3.629869010685971e-05,
      "loss": 0.0934,
      "step": 15900
    },
    {
      "epoch": 0.5515339538090314,
      "grad_norm": 1.1138217449188232,
      "learning_rate": 3.6212512926577044e-05,
      "loss": 0.0858,
      "step": 16000
    },
    {
      "epoch": 0.5549810410203379,
      "grad_norm": 1.5042248964309692,
      "learning_rate": 3.612633574629438e-05,
      "loss": 0.0942,
      "step": 16100
    },
    {
      "epoch": 0.5584281282316442,
      "grad_norm": 2.105802536010742,
      "learning_rate": 3.604015856601172e-05,
      "loss": 0.0846,
      "step": 16200
    },
    {
      "epoch": 0.5618752154429507,
      "grad_norm": 1.508837342262268,
      "learning_rate": 3.595398138572906e-05,
      "loss": 0.0932,
      "step": 16300
    },
    {
      "epoch": 0.5653223026542572,
      "grad_norm": 0.948388397693634,
      "learning_rate": 3.58678042054464e-05,
      "loss": 0.083,
      "step": 16400
    },
    {
      "epoch": 0.5687693898655636,
      "grad_norm": 1.744382619857788,
      "learning_rate": 3.578162702516374e-05,
      "loss": 0.0842,
      "step": 16500
    },
    {
      "epoch": 0.5722164770768701,
      "grad_norm": 0.9744680523872375,
      "learning_rate": 3.569544984488108e-05,
      "loss": 0.084,
      "step": 16600
    },
    {
      "epoch": 0.5756635642881764,
      "grad_norm": 1.2894790172576904,
      "learning_rate": 3.5609272664598417e-05,
      "loss": 0.083,
      "step": 16700
    },
    {
      "epoch": 0.5791106514994829,
      "grad_norm": 1.455722451210022,
      "learning_rate": 3.552309548431575e-05,
      "loss": 0.0868,
      "step": 16800
    },
    {
      "epoch": 0.5825577387107894,
      "grad_norm": 1.1007914543151855,
      "learning_rate": 3.543691830403309e-05,
      "loss": 0.0961,
      "step": 16900
    },
    {
      "epoch": 0.5860048259220958,
      "grad_norm": 2.1307599544525146,
      "learning_rate": 3.535074112375043e-05,
      "loss": 0.0896,
      "step": 17000
    },
    {
      "epoch": 0.5894519131334023,
      "grad_norm": 1.3085155487060547,
      "learning_rate": 3.526456394346777e-05,
      "loss": 0.085,
      "step": 17100
    },
    {
      "epoch": 0.5928990003447088,
      "grad_norm": 1.2051047086715698,
      "learning_rate": 3.517838676318511e-05,
      "loss": 0.0825,
      "step": 17200
    },
    {
      "epoch": 0.5963460875560151,
      "grad_norm": 2.006253242492676,
      "learning_rate": 3.509220958290245e-05,
      "loss": 0.0801,
      "step": 17300
    },
    {
      "epoch": 0.5997931747673216,
      "grad_norm": 1.3147321939468384,
      "learning_rate": 3.500603240261979e-05,
      "loss": 0.0978,
      "step": 17400
    },
    {
      "epoch": 0.603240261978628,
      "grad_norm": 2.936457395553589,
      "learning_rate": 3.491985522233713e-05,
      "loss": 0.0889,
      "step": 17500
    },
    {
      "epoch": 0.6066873491899345,
      "grad_norm": 3.089320659637451,
      "learning_rate": 3.4833678042054466e-05,
      "loss": 0.0867,
      "step": 17600
    },
    {
      "epoch": 0.610134436401241,
      "grad_norm": 1.1666717529296875,
      "learning_rate": 3.47475008617718e-05,
      "loss": 0.0779,
      "step": 17700
    },
    {
      "epoch": 0.6135815236125474,
      "grad_norm": 3.4692132472991943,
      "learning_rate": 3.466132368148914e-05,
      "loss": 0.0847,
      "step": 17800
    },
    {
      "epoch": 0.6170286108238539,
      "grad_norm": 1.6273201704025269,
      "learning_rate": 3.4575146501206484e-05,
      "loss": 0.0802,
      "step": 17900
    },
    {
      "epoch": 0.6204756980351603,
      "grad_norm": 3.0228211879730225,
      "learning_rate": 3.448896932092382e-05,
      "loss": 0.081,
      "step": 18000
    },
    {
      "epoch": 0.6239227852464667,
      "grad_norm": 1.708149790763855,
      "learning_rate": 3.440279214064116e-05,
      "loss": 0.0783,
      "step": 18100
    },
    {
      "epoch": 0.6273698724577732,
      "grad_norm": 2.000412940979004,
      "learning_rate": 3.43166149603585e-05,
      "loss": 0.0875,
      "step": 18200
    },
    {
      "epoch": 0.6308169596690796,
      "grad_norm": 2.5260279178619385,
      "learning_rate": 3.423043778007584e-05,
      "loss": 0.0821,
      "step": 18300
    },
    {
      "epoch": 0.6342640468803861,
      "grad_norm": 1.052331566810608,
      "learning_rate": 3.414426059979318e-05,
      "loss": 0.0827,
      "step": 18400
    },
    {
      "epoch": 0.6377111340916926,
      "grad_norm": 1.7949557304382324,
      "learning_rate": 3.4058083419510515e-05,
      "loss": 0.0871,
      "step": 18500
    },
    {
      "epoch": 0.6411582213029989,
      "grad_norm": 1.8072658777236938,
      "learning_rate": 3.397190623922785e-05,
      "loss": 0.0877,
      "step": 18600
    },
    {
      "epoch": 0.6446053085143054,
      "grad_norm": 0.4995866119861603,
      "learning_rate": 3.388572905894519e-05,
      "loss": 0.1012,
      "step": 18700
    },
    {
      "epoch": 0.6480523957256119,
      "grad_norm": 1.5025924444198608,
      "learning_rate": 3.379955187866253e-05,
      "loss": 0.0845,
      "step": 18800
    },
    {
      "epoch": 0.6514994829369183,
      "grad_norm": 3.4507195949554443,
      "learning_rate": 3.371337469837987e-05,
      "loss": 0.0893,
      "step": 18900
    },
    {
      "epoch": 0.6549465701482248,
      "grad_norm": 4.858737945556641,
      "learning_rate": 3.362719751809721e-05,
      "loss": 0.0863,
      "step": 19000
    },
    {
      "epoch": 0.6583936573595311,
      "grad_norm": 0.33518657088279724,
      "learning_rate": 3.354102033781455e-05,
      "loss": 0.0819,
      "step": 19100
    },
    {
      "epoch": 0.6618407445708376,
      "grad_norm": 1.6850634813308716,
      "learning_rate": 3.345484315753189e-05,
      "loss": 0.0829,
      "step": 19200
    },
    {
      "epoch": 0.6652878317821441,
      "grad_norm": 1.4179253578186035,
      "learning_rate": 3.336866597724922e-05,
      "loss": 0.0773,
      "step": 19300
    },
    {
      "epoch": 0.6687349189934505,
      "grad_norm": 2.0506012439727783,
      "learning_rate": 3.3282488796966564e-05,
      "loss": 0.0889,
      "step": 19400
    },
    {
      "epoch": 0.672182006204757,
      "grad_norm": 2.1030609607696533,
      "learning_rate": 3.3196311616683905e-05,
      "loss": 0.0807,
      "step": 19500
    },
    {
      "epoch": 0.6756290934160635,
      "grad_norm": 4.461592674255371,
      "learning_rate": 3.311013443640124e-05,
      "loss": 0.0901,
      "step": 19600
    },
    {
      "epoch": 0.6790761806273699,
      "grad_norm": 0.7312396168708801,
      "learning_rate": 3.302395725611858e-05,
      "loss": 0.0815,
      "step": 19700
    },
    {
      "epoch": 0.6825232678386763,
      "grad_norm": 1.7727186679840088,
      "learning_rate": 3.2937780075835924e-05,
      "loss": 0.0881,
      "step": 19800
    },
    {
      "epoch": 0.6859703550499827,
      "grad_norm": 0.8808634877204895,
      "learning_rate": 3.285160289555326e-05,
      "loss": 0.0863,
      "step": 19900
    },
    {
      "epoch": 0.6894174422612892,
      "grad_norm": 1.9605623483657837,
      "learning_rate": 3.27654257152706e-05,
      "loss": 0.0706,
      "step": 20000
    }
  ],
  "logging_steps": 100,
  "max_steps": 58020,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5021472522240000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
